# Vision Artificial - Control por Mirada v2.0

Sistema avanzado de control del cursor mediante seguimiento de la mirada con **autenticaciÃ³n facial**, arquitectura modular y persistencia de datos.

## ğŸ¯ DescripciÃ³n

Sistema profesional de control por mirada que incluye:

- **AutenticaciÃ³n facial biomÃ©trica**: Solo el usuario registrado puede usar el sistema
- **Base de datos SQLite**: Persistencia de usuarios, configuraciones y calibraciones
- **Arquitectura modular**: CÃ³digo organizado, mantenible y escalable
- **Sistema de logging**: DiagnÃ³stico completo de eventos y errores
- **ConfiguraciÃ³n persistente**: Tus ajustes se guardan automÃ¡ticamente

## ğŸ“‚ Versiones Disponibles

- **`main.py`**: Nueva versiÃ³n 2.0 con autenticaciÃ³n y arquitectura modular (RECOMENDADO)
- **`gaze_control.py`**: VersiÃ³n legacy sin autenticaciÃ³n (para referencia)
- **`mouse_iris_min.py`**: VersiÃ³n minimalista de prueba
- **`test_iris.py`**: Script de verificaciÃ³n de detecciÃ³n de iris

## âœ¨ CaracterÃ­sticas Principales (v2.0)

### ğŸ” AutenticaciÃ³n y Seguridad
- âœ… Registro de usuario Ãºnico con captura de mÃºltiples muestras faciales
- âœ… AutenticaciÃ³n biomÃ©trica continua durante el uso
- âœ… Base de datos SQLite local para almacenar perfiles
- âœ… Rechazo automÃ¡tico de usuarios no autorizados

### ğŸ® Control por Mirada
- âœ… Filtro OneEuro adaptativo para movimientos suaves
- âœ… Sistema de calibraciÃ³n de 9 puntos con persistencia
- âœ… Zona muerta configurable para estabilidad
- âœ… Sensibilidad ajustable en tiempo real
- âœ… Scroll automÃ¡tico por zonas de pantalla

### ğŸ‘ï¸ Gestos Inteligentes
- âœ… GuiÃ±o izquierdo corto â†’ Click izquierdo
- âœ… GuiÃ±o izquierdo SOSTENIDO (~0.5s) â†’ **Click derecho** (NUEVO)
- âœ… Doble guiÃ±o izquierdo â†’ Avanzar pÃ¡gina
- âœ… GuiÃ±o derecho corto â†’ Retroceder pÃ¡gina
- âœ… Ojo derecho cerrado + Mover derecha â†’ **Siguiente pestaÃ±a** (NUEVO)
- âœ… Ojo derecho cerrado + Mover izquierda â†’ **PestaÃ±a anterior** (NUEVO)
- âœ… Dwell click â†’ Click por mirada sostenida (opcional)

### ğŸ—‚ï¸ Sistema Modular
- âœ… Arquitectura de cÃ³digo organizada y mantenible
- âœ… Sistema de logging completo con archivos diarios
- âœ… Manejo robusto de errores
- âœ… ConfiguraciÃ³n JSON persistente
- âœ… SeparaciÃ³n de responsabilidades (MVC-like)

### ğŸ“Š Persistencia de Datos
- âœ… Historial de sesiones de usuario
- âœ… EstadÃ­sticas de uso
- âœ… Calibraciones guardadas automÃ¡ticamente
- âœ… Configuraciones personalizadas por usuario

## ğŸ› ï¸ Requisitos

- **Python 3.10** (recomendado) o Python 3.7+
- CÃ¡mara web
- Windows (probado), macOS o Linux

## ğŸ“¦ InstalaciÃ³n

> **âš ï¸ Importante**: Se recomienda usar **Python 3.10** para mejor compatibilidad con MediaPipe y todas las dependencias.

1. Verifica tu versiÃ³n de Python:
```bash
python --version
```
Si no tienes Python 3.10, descÃ¡rgalo desde [python.org](https://www.python.org/downloads/)

2. Clona el repositorio:
```bash
git clone https://github.com/tu-usuario/vision-artificial.git
cd vision-artificial
```

3. Crea un entorno virtual:
```bash
python -m venv .venv
```

4. Activa el entorno virtual:
- Windows:
```bash
.venv\Scripts\activate
```
- macOS/Linux:
```bash
source .venv/bin/activate
```

5. Instala las dependencias:
```bash
pip install -r requirements.txt
```

## ğŸš€ Uso

### VersiÃ³n 2.0 con AutenticaciÃ³n (RECOMENDADA)

```bash
python main.py
```

**Primera vez:**
1. Ingresa tu nombre de usuario
2. Mira a la cÃ¡mara para registrar tu rostro (10 muestras)
3. AutentÃ­cate mirando a la cÃ¡mara
4. Realiza la calibraciÃ³n presionando `c`

**Siguientes usos:**
1. Autentica mirando a la cÃ¡mara
2. El sistema carga automÃ¡ticamente tu calibraciÃ³n y configuraciones
3. Â¡Listo para usar!

### VersiÃ³n Legacy (sin autenticaciÃ³n)

```bash
python gaze_control.py
```

#### Controles:
- `c`: Iniciar calibraciÃ³n de 9 puntos
- `r`: Resetear calibraciÃ³n
- `d`: Activar/desactivar modo debug
- `+/-`: Ajustar sensibilidad (GAIN)
- `g`: Activar/desactivar dwell click
- `q`: Salir

#### Proceso de calibraciÃ³n:
1. Presiona `c` para iniciar
2. Mira fijamente cada uno de los 9 cÃ­rculos amarillos que aparecen
3. MantÃ©n la mirada durante 0.4 segundos en cada punto
4. El sistema se calibrarÃ¡ automÃ¡ticamente

## âš™ï¸ ConfiguraciÃ³n

Puedes ajustar los parÃ¡metros en `gaze_control.py`:

```python
GAIN = 1.20              # Sensibilidad del movimiento
DEADZONE = 0.015         # Zona muerta para micro-movimientos
WINK_THRESH = 0.20       # Umbral de detecciÃ³n de guiÃ±o
DWELL_TIME = 0.70        # Tiempo para dwell click (segundos)
SCROLL_BAND = 0.08       # TamaÃ±o de banda de scroll
SCROLL_STEP = 80         # Velocidad de scroll
```

## ğŸ¯ CÃ³mo funciona

### Pipeline de Procesamiento (v2.0)

1. **AutenticaciÃ³n Inicial**
   - Captura embedding facial del usuario
   - Almacena en base de datos SQLite
   - Verifica identidad usando similitud coseno

2. **DetecciÃ³n Facial** (MediaPipe Face Mesh)
   - 478 landmarks faciales
   - Centros de iris (puntos 468 y 473)
   - Eye Aspect Ratio para gestos

3. **Filtrado y Suavizado**
   - Filtro OneEuro adaptativo
   - Zona muerta configurable
   - ReducciÃ³n de jitter

4. **CalibraciÃ³n Personalizada**
   - TransformaciÃ³n afÃ­n 2D
   - 9 puntos de calibraciÃ³n
   - Guardado automÃ¡tico por usuario

5. **Control del Mouse**
   - Mapeo gaze-to-screen
   - Gestos mediante guiÃ±os
   - Dwell click opcional
   - Scroll automÃ¡tico

6. **VerificaciÃ³n Continua**
   - Re-autenticaciÃ³n cada 2 segundos
   - Bloqueo si usuario no reconocido

## ğŸ”§ SoluciÃ³n de problemas

### La cÃ¡mara no se abre
- Verifica que no haya otras aplicaciones usando la cÃ¡mara
- Prueba cambiar `cv.CAP_DSHOW` por `0` en el cÃ³digo

### Movimientos muy bruscos
- Aumenta la zona muerta (DEADZONE)
- Ajusta los parÃ¡metros del filtro OneEuro
- Realiza la calibraciÃ³n

### No detecta guiÃ±os
- Ajusta WINK_THRESH (valores mÃ¡s altos = mÃ¡s sensible)
- AsegÃºrate de tener buena iluminaciÃ³n

## ğŸ“ Licencia

MIT License - Ver archivo LICENSE para mÃ¡s detalles

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Haz fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/amazing-feature`)
3. Commit tus cambios (`git commit -m 'Add amazing feature'`)
4. Push a la rama (`git push origin feature/amazing-feature`)
5. Abre un Pull Request

## ğŸ“– DocumentaciÃ³n Adicional

Para una guÃ­a detallada de uso, consulta [GUIDE.md](GUIDE.md)

## ğŸ—ï¸ Arquitectura del Proyecto

```
vision-artificial/
â”œâ”€â”€ main.py                     # Punto de entrada v2.0
â”œâ”€â”€ gaze_control.py             # VersiÃ³n legacy
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ auth/                   # AutenticaciÃ³n facial
â”‚   â”‚   â”œâ”€â”€ face_auth.py        # Detector y verificador facial
â”‚   â”‚   â””â”€â”€ user_manager.py     # Gestor de usuarios
â”‚   â”œâ”€â”€ core/                   # Componentes principales
â”‚   â”‚   â”œâ”€â”€ filters.py          # Filtros OneEuro y EMA
â”‚   â”‚   â”œâ”€â”€ face_detector.py    # Detector MediaPipe
â”‚   â”‚   â”œâ”€â”€ gaze_tracker.py     # Seguimiento de mirada
â”‚   â”‚   â”œâ”€â”€ mouse_controller.py # Control del mouse
â”‚   â”‚   â””â”€â”€ calibration.py      # Sistema de calibraciÃ³n
â”‚   â”œâ”€â”€ database/               # Persistencia
â”‚   â”‚   â””â”€â”€ db_manager.py       # Gestor SQLite
â”‚   â”œâ”€â”€ ui/                     # Interfaz de usuario
â”‚   â”‚   â””â”€â”€ main_window.py      # Ventana principal
â”‚   â””â”€â”€ utils/                  # Utilidades
â”‚       â”œâ”€â”€ logger.py           # Sistema de logs
â”‚       â”œâ”€â”€ config.py           # ConfiguraciÃ³n
â”‚       â””â”€â”€ error_handler.py    # Manejo de errores
â””â”€â”€ data/                       # Datos generados
    â”œâ”€â”€ users.db                # Base de datos
    â”œâ”€â”€ config.json             # ConfiguraciÃ³n
    â””â”€â”€ logs/                   # Archivos de log
```

## ğŸ”„ MigraciÃ³n desde v1.0

Si usabas `gaze_control.py`:

1. La versiÃ³n legacy sigue funcionando
2. Para usar v2.0, ejecuta `python main.py`
3. Registra tu usuario la primera vez
4. Tus configuraciones anteriores en `gaze_control.py` se pueden aplicar manualmente en `data/config.json`

## ğŸ‘¤ Autor

Desarrollado como proyecto de Inteligencia Artificial

## ğŸ™ Agradecimientos

- [MediaPipe](https://google.github.io/mediapipe/) por la detecciÃ³n facial
- [OpenCV](https://opencv.org/) por el procesamiento de video
- [PyAutoGUI](https://pyautogui.readthedocs.io/) por el control del mouse
